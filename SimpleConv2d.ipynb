{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jigjid/github_task/blob/main/SimpleConv2d.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "yyTfdhSOcR6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "rmTeMedYcOFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''-------------------------\n",
        "initialization class\n",
        "-------------------------'''\n",
        "class SimpleInitializerConv2d:\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "    def W(self, F, C, FH, FW):\n",
        "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
        "    def B(self, F):\n",
        "        return np.zeros(F)\n",
        "\n",
        "\n",
        "class HeInitializer():\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = math.sqrt(2 / n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        return B\n",
        "        \n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, *shape):\n",
        "        W = self.sigma * np.random.randn(*shape)\n",
        "        return W\n",
        "    def B(self, *shape):\n",
        "        B = self.sigma * np.random.randn(*shape)\n",
        "        return B\n",
        "\n",
        "\n",
        "'''------------------------\n",
        "optimization method\n",
        "-----------------------'''\n",
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.clip(A, 0, None)\n",
        "    def backward(self, dZ):\n",
        "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        return\n",
        "\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW = 1\n",
        "        self.HB = 1\n",
        "    def update(self, layer):\n",
        "        self.HW += layer.dW**2\n",
        "        self.HB += layer.dB**2\n",
        "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
        "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n",
        "        return self.Z\n",
        "    def backward(self, Y):\n",
        "        self.loss = self.loss_func(Y)\n",
        "        return self.Z - Y\n",
        "    def loss_func(self, Y, Z=None):\n",
        "        if Z is None:\n",
        "            Z = self.Z\n",
        "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))"
      ],
      "metadata": {
        "id": "Z3nUJgI3cFmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        A = X@self.W + self.B\n",
        "        return A\n",
        "    def backward(self, dA):\n",
        "        dZ = dA@self.W.T\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = self.X.T@dA\n",
        "        self.optimizer.update(self)\n",
        "        return dZ"
      ],
      "metadata": {
        "id": "BNr_-KZbvutZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1] \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "metadata": {
        "id": "J6Dh2iolv0lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 1: Creating a two-dimensional convolutional layer**"
      ],
      "metadata": {
        "id": "VGJsfeLIbkh0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAFxhGlCa5zL"
      },
      "outputs": [],
      "source": [
        "class SimpleConv2d():\n",
        "    def __init__(self, F, C, FH, FW, P, S,initializer=None,optimizer=None,activation=None):\n",
        "        self.P = P\n",
        "        self.S = S\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        self.W = self.initializer.W(F,C,FH,FW)\n",
        "        self.B = self.initializer.B(F)\n",
        "\n",
        "\n",
        "    def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
        "        '''\n",
        "        It accepts height H, width W, padding height PH, \n",
        "        padding width PW, filter height FH, filter width FW, \n",
        "        stride height SH, and stride width SW as arguments.\n",
        "        --------------------------------------------\n",
        "        Calculating the height of the output\n",
        "        --------------------------------------------\n",
        "        Calculating the width of the output\n",
        "        '''\n",
        "        OH = (H +2*PH -FH)/SH +1\n",
        "        OW = (W +2*PW -FW)/SW +1\n",
        "        return int(OH),int(OW)\n",
        "\n",
        "\n",
        "    def forward(self, X,debug=False):\n",
        "        self.X = X\n",
        "        N,C,H,W = self.X.shape\n",
        "        F,C,FH,FW = self.W.shape\n",
        "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
        "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "        A = np.zeros([N,F,OH,OW])\n",
        "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        A[n,ch,row,col] = np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]*self.W[ch,:,:,:]) +self.B[ch]\n",
        "        if debug==True:\n",
        "            return A\n",
        "        else:\n",
        "            return  self.activation.forward(A)\n",
        "\n",
        "\n",
        "\n",
        "    def backward(self, dZ,debug=False):\n",
        "        if debug==True:\n",
        "            dA = dZ\n",
        "        else:\n",
        "            dA = self.activation.backward(dZ)\n",
        "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
        "        dZ = np.zeros(self.X_pad.shape)\n",
        "        self.dW = np.zeros(self.W.shape)\n",
        "        self.dB = np.zeros(self.B.shape)\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
        "        if self.P == 0:\n",
        "            dZ = np.delete(dZ,[0,H-1],axis=2)\n",
        "            dZ = np.delete(dZ,[0,W-1],axis=3)\n",
        "        else:\n",
        "            dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
        "            dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
        "            dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "            dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(OH):\n",
        "                    for col in range(OW):\n",
        "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "        for ch in range(F):\n",
        "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2: Experiment of two-dimensional convolutional layer in small array**"
      ],
      "metadata": {
        "id": "ZH0Vivw3dyZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In Input,(1,1,4,4)\n",
        "x = np.array([[[[ 1,  2,  3,  4],\n",
        "                [ 5,  6,  7,  8],\n",
        "                [ 9, 10, 11, 12],\n",
        "                [13, 14, 15, 16]]]])\n",
        "\n",
        "#Weight,(2,3,3)\n",
        "w = np.array([[[[ 0.,  0.,  0.],\n",
        "               [ 0.,  1.,  0.],\n",
        "               [ 0., -1.,  0.]]],\n",
        "\n",
        "              [[[ 0.,  0.,  0.],\n",
        "               [ 0., -1.,  1.],\n",
        "               [ 0.,  0.,  0.]]]])\n",
        "\n",
        "simple_conv_2d = SimpleConv2d(F=2, C=1, FH=3, FW=3, P=0, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(0.01),activation=ReLU())\n",
        "simple_conv_2d.W = w\n",
        "A = simple_conv_2d.forward(x,True)\n",
        "\n",
        "\n",
        "da = np.array([[[[ -4,  -4], [ 10,  11]],[[  1,  -7],[  1, -11]]]])\n",
        "dZ = simple_conv_2d.backward(da,True)\n",
        "\n",
        "print(\"forward propagation: \\n{}\".format(A))\n",
        "print(\"backward propagation: \\n{}\".format(dZ))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QrOkZC-eJVz",
        "outputId": "72b9af71-2285-4f70-817d-23d171d57f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward propagation: \n",
            "[[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n",
            "backward propagation: \n",
            "[[[[-5.  4.]\n",
            "   [13. 27.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3: Output size after 2D convolution**"
      ],
      "metadata": {
        "id": "9wEHdsZWhqFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_conv_2d.output_shape2d(H=6,W=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2dcOX_phvtV",
        "outputId": "9cccbe54-87ce-4487-b54e-85452560e6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 4: Creating the Maximum Pooling Layer**"
      ],
      "metadata": {
        "id": "7G8Fe15ZixmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2D():\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "        '''--------------------------------\n",
        "        padding width P, \n",
        "        forward propagation value PA, \n",
        "        maximum value PIndex member variable\n",
        "        ---------------------------------'''\n",
        "\n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PH,PW = int(OH/self.P),int(OW/self.P)\n",
        "        self.params = N,F,OH,OW,self.P,PH,PW\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] =np.max(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "                        self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "        return self.PA\n",
        "\n",
        "\n",
        "    def backward(self,dA):\n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        for n in range(N): \n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        idx = self.Pindex[n,ch,row,col]\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            if i == idx:\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "                            else:\n",
        "                                tmp[i] = 0\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        return dP"
      ],
      "metadata": {
        "id": "vXJDgqcajCjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxpool2d = MaxPool2D(P=2)\n",
        "m = maxpool2d.forward(x)\n",
        "print(m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi9nErYIkjYs",
        "outputId": "b2cd5daa-602a-41dc-d4f8-b0bbed500451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 6.  8.]\n",
            "   [14. 16.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 5:(Advanced Task) Creating Average Pooling**"
      ],
      "metadata": {
        "id": "R_OUqfgQl5om"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AveragePool2D():\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "        '''--------------------------------\n",
        "        padding width P, \n",
        "        forward propagation value PA, \n",
        "        maximum value PIndex member variable\n",
        "        ---------------------------------'''\n",
        "\n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PH,PW = int(OH/self.P),int(OW/self.P)\n",
        "        self.params = N,F,OH,OW,self.P,PH,PW\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] =(np.average(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P]))*2\n",
        "                        #self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "        return self.PA\n",
        "\n",
        "\n",
        "    def backward(self,dA):\n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        for n in range(N): \n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        idx = self.PA[n,ch,row,col]\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            if i == idx:\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "                            else:\n",
        "                                tmp[i] = 0\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        return dP"
      ],
      "metadata": {
        "id": "bzT-hmi-mBj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avgpool2d = AveragePool2D(P=2)\n",
        "a = avgpool2d.forward(x)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjH0WgKqnXLC",
        "outputId": "cfec4786-f791-4838-f6de-fa8d813e1019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 7. 11.]\n",
            "   [23. 27.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 6: Smoothing**"
      ],
      "metadata": {
        "id": "wA4tBL_yqq-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self,X):\n",
        "        self.shape = X.shape\n",
        "        return X.reshape(len(X),-1)\n",
        "    def backward(self,X):\n",
        "        return X.reshape(self.shape)"
      ],
      "metadata": {
        "id": "Q9lOSNbWqw1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat = Flatten()\n",
        "ff = flat.forward(A)\n",
        "fb = flat.backward(ff)\n",
        "print(\"forward value: \\n{}\".format(ff))\n",
        "print(\"\\nbackward value: \\n{}\".format(fb))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kHnDVASrAnp",
        "outputId": "63d883ba-18f4-4874-8f38-49e2abe4be85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward value: \n",
            "[[-4. -4. -4. -4.  1.  1.  1.  1.]]\n",
            "\n",
            "backward value: \n",
            "[[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 7: Learning and estimation**"
      ],
      "metadata": {
        "id": "ML0511jKrdHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scratch2dCNNClassifier():\n",
        "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
        "        self.NN = NN\n",
        "        self.CNN = CNN\n",
        "        self.n_epoch = n_epoch\n",
        "        self.n_batch = n_batch\n",
        "        self.verbose = verbose\n",
        "        self.log_loss = np.zeros(self.n_epoch)\n",
        "        self.log_acc = np.zeros(self.n_epoch)\n",
        "\n",
        "\n",
        "    def loss_function(self,y,yt):\n",
        "        delta = 1e-7\n",
        "        return -np.mean(yt*np.log(y+delta))\n",
        "    def accuracy(self,Z,Y):\n",
        "        return accuracy_score(Y,Z)\n",
        "\n",
        "    def fit(self, X, y, X_val=False, y_val=False):\n",
        "        for epoch in range(self.n_epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
        "            self.loss = 0\n",
        "            for mini_X_train, mini_y_train in get_mini_batch:              \n",
        "                forward_data = mini_X_train[:,np.newaxis,:,:]\n",
        "                for layer in range(len(self.CNN)):\n",
        "                    forward_data = self.CNN[layer].forward(forward_data)\n",
        "                flt = Flatten()\n",
        "                forward_data = flt.forward(forward_data)\n",
        "                for layer in range(len(self.NN)):\n",
        "                    forward_data = self.NN[layer].forward(forward_data)\n",
        "                Z = forward_data\n",
        "                backward_data = (Z - mini_y_train)/self.n_batch\n",
        "                for layer in range(len(self.NN)-1,-1,-1):\n",
        "                    backward_data = self.NN[layer].backward(backward_data)\n",
        "                backward_data = flt.backward(backward_data)\n",
        "                for layer in range(len(self.CNN)-1,-1,-1):\n",
        "                    backward_data = self.CNN[layer].backward(backward_data)\n",
        "                self.loss += self.loss_function(Z,mini_y_train)\n",
        "                if self.verbose:\n",
        "                    print('batch loss %f'%self.loss_function(Z,mini_y_train))\n",
        "            if self.verbose:\n",
        "                print(self.loss/len(get_mini_batch),self.accuracy(self.predict(X),np.argmax(y,axis=1)))\n",
        "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
        "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "          pred_data = X[:,np.newaxis,:,:]\n",
        "          for layer in range(len(self.CNN)):\n",
        "              pred_data = self.CNN[layer].forward(pred_data)\n",
        "          pred_data = flt.forward(pred_data)\n",
        "          for layer in range(len(self.NN)):\n",
        "              pred_data = self.NN[layer].forward(pred_data)\n",
        "          return np.argmax(pred_data,axis=1)\n",
        "\n",
        "          "
      ],
      "metadata": {
        "id": "1DFqNArQs0fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN = {\n",
        "    0:FC(1960, 200, HeInitializer(), SGD(0.1)),\n",
        "    1:FC(200, 200, HeInitializer(), SGD(0.1)),\n",
        "    2:FC(200, 10, SimpleInitializer(0.1), AdaGrad(0.1)),\n",
        "}\n",
        "CNN = {\n",
        "    0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(0.1),activation=ReLU()),\n",
        "    1:MaxPool2D(2),\n",
        "}\n",
        "\n",
        "flt = Flatten()\n",
        "\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train.reshape(-1,1))\n",
        "y_val_one_hot = enc.fit_transform(y_val.reshape(-1,1))\n",
        "\n",
        "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=1,n_batch=20,verbose=True)\n",
        "cnn1.fit(X_train,y_train_one_hot)"
      ],
      "metadata": {
        "id": "LOHMWYRtt5Ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn1.predict(X_val)\n",
        "accuracy = accuracy_score(np.argmax(y_val,axis=1), y_pred)\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "hHVLgk6g8i7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "num = 36\n",
        "true_false = y_pred==y_val\n",
        "false_list = np.where(true_false==False)[0].astype(np.int)\n",
        "\n",
        "if false_list.shape[0] < num:\n",
        "    num = false_list.shape[0]\n",
        "fig = plt.figure(figsize=(6, 6))\n",
        "fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
        "for i in range(num):\n",
        "    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
        "    ax.set_title(\"{} / {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
        "    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
      ],
      "metadata": {
        "id": "PtYQkyqfzKol"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}