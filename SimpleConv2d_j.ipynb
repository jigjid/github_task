{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jigjid/github_task/blob/main/SimpleConv2d_j.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyTfdhSOcR6n"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rmTeMedYcOFY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import math\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z3nUJgI3cFmE"
      },
      "outputs": [],
      "source": [
        "'''-------------------------\n",
        "initialization class\n",
        "-------------------------'''\n",
        "class SimpleInitializerConv2d:\n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "    def W(self, F, C, FH, FW):\n",
        "        return self.sigma * np.random.randn(F,C,FH,FW)\n",
        "    def B(self, F):\n",
        "        return np.zeros(F)\n",
        "\n",
        "\n",
        "class HeInitializer():\n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = math.sqrt(2 / n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(n_nodes2)\n",
        "        return B\n",
        "        \n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    def W(self, *shape):\n",
        "        W = self.sigma * np.random.randn(*shape)\n",
        "        return W\n",
        "    def B(self, *shape):\n",
        "        B = self.sigma * np.random.randn(*shape)\n",
        "        return B\n",
        "\n",
        "\n",
        "'''------------------------\n",
        "optimization method\n",
        "-----------------------'''\n",
        "class ReLU:\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        return np.clip(A, 0, None)\n",
        "    def backward(self, dZ):\n",
        "        return dZ * np.clip(np.sign(self.A), 0, None)\n",
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        return\n",
        "\n",
        "class AdaGrad:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW = 1\n",
        "        self.HB = 1\n",
        "    def update(self, layer):\n",
        "        self.HW += layer.dW**2\n",
        "        self.HB += layer.dB**2\n",
        "        layer.W -= self.lr * np.sqrt(1/self.HW) * layer.dW\n",
        "        layer.B -= self.lr * np.sqrt(1/self.HB) * layer.dB\n",
        "\n",
        "\n",
        "class Softmax:\n",
        "    def forward(self, X):\n",
        "        self.Z = np.exp(X) / np.sum(np.exp(X), axis=1).reshape(-1,1)\n",
        "        return self.Z\n",
        "    def backward(self, Y):\n",
        "        self.loss = self.loss_func(Y)\n",
        "        return self.Z - Y\n",
        "    def loss_func(self, Y, Z=None):\n",
        "        if Z is None:\n",
        "            Z = self.Z\n",
        "        return (-1)*np.average(np.sum(Y*np.log(Z), axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BNr_-KZbvutZ"
      },
      "outputs": [],
      "source": [
        "class FC:\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.optimizer = optimizer\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "    def forward(self, X):\n",
        "        self.X = X\n",
        "        A = X@self.W + self.B\n",
        "        return A\n",
        "    def backward(self, dA):\n",
        "        dZ = dA@self.W.T\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = self.X.T@dA\n",
        "        self.optimizer.update(self)\n",
        "        return dZ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J6Dh2iolv0lg"
      },
      "outputs": [],
      "source": [
        "class GetMiniBatch:\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1] \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGJsfeLIbkh0"
      },
      "source": [
        "**Problem 1: Creating a two-dimensional convolutional layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AAFxhGlCa5zL"
      },
      "outputs": [],
      "source": [
        "class SimpleConv2d():\n",
        "    def __init__(self, F, C, FH, FW, P, S,initializer=None,optimizer=None,activation=None):\n",
        "        self.P = P\n",
        "        self.S = S\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.activation = activation\n",
        "        self.W = self.initializer.W(F,C,FH,FW)\n",
        "        self.B = self.initializer.B(F)\n",
        "\n",
        "\n",
        "    def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
        "        '''\n",
        "        It accepts height H, width W, padding height PH, \n",
        "        padding width PW, filter height FH, filter width FW, \n",
        "        stride height SH, and stride width SW as arguments.\n",
        "        --------------------------------------------\n",
        "        Calculating the height of the output\n",
        "        --------------------------------------------\n",
        "        Calculating the width of the output\n",
        "        '''\n",
        "        OH = (H +2*PH -FH)/SH +1\n",
        "        OW = (W +2*PW -FW)/SW +1\n",
        "        return int(OH),int(OW)\n",
        "\n",
        "\n",
        "    def forward(self, X,debug=False):\n",
        "        self.X = X\n",
        "        N,C,H,W = self.X.shape\n",
        "        F,C,FH,FW = self.W.shape\n",
        "        OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
        "        self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "        A = np.zeros([N,F,OH,OW])\n",
        "        self.X_pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        A[n,ch,row,col] = np.sum(self.X_pad[n,:,row:row+FH,col:col+FW]*self.W[ch,:,:,:]) +self.B[ch]\n",
        "        if debug==True:\n",
        "            return A\n",
        "        else:\n",
        "            return  self.activation.forward(A)\n",
        "\n",
        "\n",
        "\n",
        "    def backward(self, dZ,debug=False):\n",
        "        if debug==True:\n",
        "            dA = dZ\n",
        "        else:\n",
        "            dA = self.activation.backward(dZ)\n",
        "        N,C,H,W,F,FH,FW,OH,OW = self.params\n",
        "        dZ = np.zeros(self.X_pad.shape)\n",
        "        self.dW = np.zeros(self.W.shape)\n",
        "        self.dB = np.zeros(self.B.shape)\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(0,H,self.S):\n",
        "                    for col in range(0,W,self.S):\n",
        "                        if self.P == 0 and (W-2 <= col or H-2<=row):\n",
        "                            continue\n",
        "                        dZ[n,:,row:row+FH,col:col+FW] += dA[n,ch,row,col]*self.W[ch,:,:,:]\n",
        "        if self.P == 0:\n",
        "            dZ = np.delete(dZ,[0,H-1],axis=2)\n",
        "            dZ = np.delete(dZ,[0,W-1],axis=3)\n",
        "        else:\n",
        "            dl_rows = range(self.P),range(H+self.P,H+2*self.P,1)\n",
        "            dl_cols = range(self.P),range(W+self.P,W+2*self.P,1)\n",
        "            dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "            dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(OH):\n",
        "                    for col in range(OW):\n",
        "                        self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "        for ch in range(F):\n",
        "            self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "        self = self.optimizer.update(self)\n",
        "        return dZ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH0Vivw3dyZC"
      },
      "source": [
        "**Problem 2: Experiment of two-dimensional convolutional layer in small array**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QrOkZC-eJVz",
        "outputId": "800125d3-e2ed-4b98-d8d3-a96cdbc9f6ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward propagation: \n",
            "[[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n",
            "backward propagation: \n",
            "[[[[-5.  4.]\n",
            "   [13. 27.]]]]\n"
          ]
        }
      ],
      "source": [
        "#In Input,(1,1,4,4)\n",
        "x = np.array([[[[ 1,  2,  3,  4],\n",
        "                [ 5,  6,  7,  8],\n",
        "                [ 9, 10, 11, 12],\n",
        "                [13, 14, 15, 16]]]])\n",
        "\n",
        "#Weight,(2,3,3)\n",
        "w = np.array([[[[ 0.,  0.,  0.],\n",
        "               [ 0.,  1.,  0.],\n",
        "               [ 0., -1.,  0.]]],\n",
        "\n",
        "              [[[ 0.,  0.,  0.],\n",
        "               [ 0., -1.,  1.],\n",
        "               [ 0.,  0.,  0.]]]])\n",
        "\n",
        "simple_conv_2d = SimpleConv2d(F=2, C=1, FH=3, FW=3, P=0, S=1,initializer=SimpleInitializerConv2d(),optimizer=SGD(0.01),activation=ReLU())\n",
        "simple_conv_2d.W = w\n",
        "A = simple_conv_2d.forward(x,True)\n",
        "\n",
        "\n",
        "da = np.array([[[[ -4,  -4], [ 10,  11]],[[  1,  -7],[  1, -11]]]])\n",
        "dZ = simple_conv_2d.backward(da,True)\n",
        "\n",
        "print(\"forward propagation: \\n{}\".format(A))\n",
        "print(\"backward propagation: \\n{}\".format(dZ))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wEHdsZWhqFr"
      },
      "source": [
        "**Problem 3: Output size after 2D convolution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2dcOX_phvtV",
        "outputId": "70f7b1d2-2334-4213-c37b-279ca69ae33f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "simple_conv_2d.output_shape2d(H=6,W=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G8Fe15ZixmS"
      },
      "source": [
        "**Problem 4: Creating the Maximum Pooling Layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vXJDgqcajCjK"
      },
      "outputs": [],
      "source": [
        "class MaxPool2D():\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "        '''--------------------------------\n",
        "        padding width P, \n",
        "        forward propagation value PA, \n",
        "        maximum value PIndex member variable\n",
        "        ---------------------------------'''\n",
        "\n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PH,PW = int(OH/self.P),int(OW/self.P)\n",
        "        self.params = N,F,OH,OW,self.P,PH,PW\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] =np.max(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "                        self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "        return self.PA\n",
        "\n",
        "\n",
        "    def backward(self,dA):\n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        for n in range(N): \n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        idx = self.Pindex[n,ch,row,col]\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            if i == idx:\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "                            else:\n",
        "                                tmp[i] = 0\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        return dP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi9nErYIkjYs",
        "outputId": "ec6ba731-4e74-45c7-8617-551a884cc072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 6.  8.]\n",
            "   [14. 16.]]]]\n"
          ]
        }
      ],
      "source": [
        "maxpool2d = MaxPool2D(P=2)\n",
        "m = maxpool2d.forward(x)\n",
        "print(m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_OUqfgQl5om"
      },
      "source": [
        "**Problem 5:(Advanced Task) Creating Average Pooling**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bzT-hmi-mBj1"
      },
      "outputs": [],
      "source": [
        "class AveragePool2D():\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "        '''--------------------------------\n",
        "        padding width P, \n",
        "        forward propagation value PA, \n",
        "        maximum value PIndex member variable\n",
        "        ---------------------------------'''\n",
        "\n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PH,PW = int(OH/self.P),int(OW/self.P)\n",
        "        self.params = N,F,OH,OW,self.P,PH,PW\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] =(np.average(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P]))*2\n",
        "                        #self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "        return self.PA\n",
        "\n",
        "\n",
        "    def backward(self,dA):\n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        for n in range(N): \n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        idx = self.PA[n,ch,row,col]\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            if i == idx:\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "                            else:\n",
        "                                tmp[i] = 0\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        return dP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjH0WgKqnXLC",
        "outputId": "abfe2873-c001-404a-c206-dac0953deb88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[ 7. 11.]\n",
            "   [23. 27.]]]]\n"
          ]
        }
      ],
      "source": [
        "avgpool2d = AveragePool2D(P=2)\n",
        "a = avgpool2d.forward(x)\n",
        "print(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA4tBL_yqq-v"
      },
      "source": [
        "**Problem 6: Smoothing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Q9lOSNbWqw1b"
      },
      "outputs": [],
      "source": [
        "class Flatten:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    def forward(self,X):\n",
        "        self.shape = X.shape\n",
        "        return X.reshape(len(X),-1)\n",
        "    def backward(self,X):\n",
        "        return X.reshape(self.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kHnDVASrAnp",
        "outputId": "bdc6c478-c36e-4bd8-a01d-10750b1ad278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "forward value: \n",
            "[[-4. -4. -4. -4.  1.  1.  1.  1.]]\n",
            "\n",
            "backward value: \n",
            "[[[[-4. -4.]\n",
            "   [-4. -4.]]\n",
            "\n",
            "  [[ 1.  1.]\n",
            "   [ 1.  1.]]]]\n"
          ]
        }
      ],
      "source": [
        "flat = Flatten()\n",
        "ff = flat.forward(A)\n",
        "fb = flat.backward(ff)\n",
        "print(\"forward value: \\n{}\".format(ff))\n",
        "print(\"\\nbackward value: \\n{}\".format(fb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML0511jKrdHN"
      },
      "source": [
        "**Problem 7: Learning and estimation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1DFqNArQs0fu"
      },
      "outputs": [],
      "source": [
        "class Scratch2dCNNClassifier():\n",
        "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
        "        self.NN = NN\n",
        "        self.CNN = CNN\n",
        "        self.n_epoch = n_epoch\n",
        "        self.n_batch = n_batch\n",
        "        self.verbose = verbose\n",
        "        self.log_loss = np.zeros(self.n_epoch)\n",
        "        self.log_acc = np.zeros(self.n_epoch)\n",
        "\n",
        "\n",
        "    def loss_function(self,y,yt):\n",
        "        delta = 1e-7\n",
        "        return -np.mean(yt*np.log(y+delta))\n",
        "    def accuracy(self,Z,Y):\n",
        "        return accuracy_score(Y,Z)\n",
        "\n",
        "    def fit(self, X, y, X_val=False, y_val=False):\n",
        "        for epoch in range(self.n_epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
        "            self.loss = 0\n",
        "            for mini_X_train, mini_y_train in get_mini_batch:              \n",
        "                forward_data = mini_X_train[:,np.newaxis,:,:]\n",
        "                for layer in range(len(self.CNN)):\n",
        "                    forward_data = self.CNN[layer].forward(forward_data)\n",
        "                flt = Flatten()\n",
        "                forward_data = flt.forward(forward_data)\n",
        "                for layer in range(len(self.NN)):\n",
        "                    forward_data = self.NN[layer].forward(forward_data)\n",
        "                Z = forward_data\n",
        "                backward_data = (Z - mini_y_train)/self.n_batch\n",
        "                for layer in range(len(self.NN)-1,-1,-1):\n",
        "                    backward_data = self.NN[layer].backward(backward_data)\n",
        "                backward_data = flt.backward(backward_data)\n",
        "                for layer in range(len(self.CNN)-1,-1,-1):\n",
        "                    backward_data = self.CNN[layer].backward(backward_data)\n",
        "                self.loss += self.loss_function(Z,mini_y_train)\n",
        "                if self.verbose:\n",
        "                    print('batch loss %f'%self.loss_function(Z,mini_y_train))\n",
        "            if self.verbose:\n",
        "                print(self.loss/len(get_mini_batch),self.accuracy(self.predict(X),np.argmax(y,axis=1)))\n",
        "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
        "            self.log_acc[epoch] = self.accuracy(self.predict(X),np.argmax(y,axis=1))\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, X):\n",
        "          pred_data = X[:,np.newaxis,:,:]\n",
        "          for layer in range(len(self.CNN)):\n",
        "              pred_data = self.CNN[layer].forward(pred_data)\n",
        "          pred_data = flt.forward(pred_data)\n",
        "          for layer in range(len(self.NN)):\n",
        "              pred_data = self.NN[layer].forward(pred_data)\n",
        "          return np.argmax(pred_data,axis=1)\n",
        "\n",
        "          "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "LOHMWYRtt5Ht"
      },
      "outputs": [],
      "source": [
        "class MaxPool2D():\n",
        "\n",
        "    def __init__(self,P):\n",
        "\n",
        "        self.P = P\n",
        "\n",
        "        self.PA = None\n",
        "\n",
        "        self.Pindex = None\n",
        "\n",
        "    def forward(self,A):\n",
        "\n",
        "        N,F,OH,OW = A.shape\n",
        "\n",
        "        PH,PW = int(OH/self.P),int(OW/self.P)\n",
        "\n",
        "        self.params = N,F,OH,OW,self.P,PH,PW\n",
        "\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "\n",
        "        for n in range(N):\n",
        "\n",
        "            for ch in range(F):\n",
        "\n",
        "                for row in range(PH):\n",
        "\n",
        "                    for col in range(PW):\n",
        "\n",
        "                        self.PA[n,ch,row,col] =np.max(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "\n",
        "                        self.Pindex[n,ch,row,col] = np.argmax(A[n,ch,row*self.P:row*self.P+self.P,col*self.P:col*self.P+self.P])\n",
        "\n",
        "        return self.PA\n",
        "\n",
        "    def backward(self,dA):\n",
        "\n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "\n",
        "        for n in range(N):\n",
        "\n",
        "            for ch in range(F):\n",
        "\n",
        "                for row in range(PH):\n",
        "\n",
        "                    for col in range(PW):\n",
        "\n",
        "                        idx = self.Pindex[n,ch,row,col]\n",
        "\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "\n",
        "                        for i in range(PS*PS):\n",
        "\n",
        "                            if i == idx:\n",
        "\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "\n",
        "                            else:\n",
        "\n",
        "                                tmp[i] = 0\n",
        "\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "\n",
        "        return dP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hHVLgk6g8i7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9942502e-cd18-4d15-9903-4e0cd39cfade"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 1.,  2.,  3.,  4.],\n",
              "         [ 5.,  6.,  7.,  8.],\n",
              "         [ 9., 10., 11., 12.],\n",
              "         [13., 14., 15., 16.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "MaxPool = MaxPool2D(P=1) # P-The number of padding\n",
        "\n",
        "a = MaxPool.forward(x)\n",
        "\n",
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtYQkyqfzKol"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}